#!/bin/bash
# ############################################################################################
# File: ........: deployTKGmc
# Language .....: bash 
# Author .......: Sacha Dubois, VMware
# Description ..: Tanzu Demo Hub - Deploy TKG Management Cluster
# ############################################################################################

export TANZU_DEMO_HUB=$(cd "$(pwd)/$(dirname $0)"; pwd)
export TDHPATH=$(cd "$(pwd)/$(dirname $0)"; pwd)
export DEBUG=0
export NATIVE=0                ## NATIVE=1 r(un on local host), NATIVE=0 (run within docker)
export DEPLOY_TKG_CLEAN=0
export TDH_TOOLS=tdh-tools
export TDH_TOOLS_CONTAINER_TYPE=tkg

# --- SETTING FOR TDH-TOOLS ---
export START_COMMAND="$*"
export CMD_EXEC=$(basename $0)
export CMD_ARGS=$*

# --- SOUTCE FOUNCTIONS AND USER ENVIRONMENT ---
[ -f $TANZU_DEMO_HUB/functions ] && . $TANZU_DEMO_HUB/functions
[ -f $HOME/.tanzu-demo-hub.cfg ] && . $HOME/.tanzu-demo-hub.cfg

# --- CHECK FOR BASIC COMANDS ---
checkCLIcommands        BASIC

usage() {
  str=$(ls -1 $TDHPATH/files/tdh-tools/tdh-tools-tkg-*.cfg | sed -e 's/^.*tools-tkg-//g' -e 's/\.cfg//g' | paste - - | awk '{ printf("%s or %s\n", $1, $2) }')
  echo "USAGE: $0 [oprions] -d <deployment> -v <tkg-version>"
  echo "            Options:  -d <deployment.cfg>         # TKG Management Cluster Deployment Name"
  echo "                      -v <tkg-version>            # TKG Version (ie. $str)"
  echo ""
  echo "                      --delete                    # Delete Management Cluster and Jump Server"
  echo "                      --debug                     # default (disabled)"
  echo "                      --native                    # Use 'native' installed tools instead of the tdh-tools container"
}

while [ "$1" != "" ]; do
  case $1 in
    -d)            DEPLOY_TKG_TEMPLATE=$2;;
    -v)            DEPLOY_TKG_VERSION=$2;;
    --delete)      DEPLOY_TKG_CLEAN=1;;
    --debug)       DEBUG=1;;
    --native)      NATIVE=1;;
  esac
  shift
done

if [ "${DEPLOY_TKG_TEMPLATE}" == "" ]; then
  listTKGmcDeployments
  usage; exit 0
fi

if [ "${DEPLOY_TKG_VERSION}" != "" ]; then
  if [ ! -f $TDHPATH/files/tdh-tools/tdh-tools-tkg-${DEPLOY_TKG_VERSION}.cfg ]; then 
    str=$(ls -1 $TDHPATH/files/tdh-tools/tdh-tools-tkg-*.cfg | sed -e 's/^.*tools-tkg-//g' -e 's/\.cfg//g' | paste - - | awk '{ printf("%s or %s\n", $1, $2) }') 
    echo "ERROR: Unsuported TKG Release $DEPLOY_TKG_VERSION, ($str) are supported"
    exit 0
  fi
else
  echo "ERROR: Please specifiy option -v <tkg-version>" 
  usage; exit 0
fi

# --- VERIFY DEPLOYMENT ---
if [ ! -f ${TDHPATH}/deployments/${DEPLOY_TKG_TEMPLATE} ]; then
  echo "ERROR: Deployment file $DEPLOY_TKG_TEMPLATE can not be found in ${TDHPATH}/deployments"
  exit 1
else
  . ${TDHPATH}/deployments/${DEPLOY_TKG_TEMPLATE}
fi

#############################################################################################################################
################################### EXECUTING CODE WITHIN  TDH-TOOLS DOCKER CONTAINER  ######################################
#############################################################################################################################
runTDHtools tkg $DEPLOY_TKG_VERSION "Deploy TKG Management Cluster" "/home/tanzu/tanzu-demo-hub/$CMD_EXEC" "$CMD_ARGS"

export TDH_DEPLOYMENT_ENV_NAME=$TDH_TKGMC_INFRASTRUCTURE
export TKG_CONFIG=~/.tanzu-demo-hub/$TDH_TKGMC_CONFIG

cleanupEnvironment() {
  # --- CHECK FOR WORKLOAD CLUSTERS ---
  tanzu cluster list >/dev/null 2>&1; ret=$?
  if [ $ret -eq 0 ]; then
    cnt=$(tanzu cluster list 2>/dev/null | sed '1d' | wc -l | sed 's/  *//g') 
    if [ $cnt -gt 0 ]; then
      tanzu cluster list
      messageLine
      echo "ERROR: TKG Workload Clusters are still running, please delete them first."
      for n in $(tanzu cluster list | sed '1d' | awk '{ print $1 }'); do
        echo "       => tanzu cluster delete $n -y"
      done
      exit 1
    fi
  fi

  cleanKindCluster

  # --- DEREGISTER TMC REGISTRATION
  tmc managementcluster get $TDH_TKGMC_NAME-$TDH_USER > /dev/null 2>&1; ret=$?
  if [ $ret -eq 0 ]; then
    stt=$(tmc managementcluster get $TDH_TKGMC_NAME-$TDH_USER -o json 2>/dev/null | jq -r '.status.phase')
    if [ "$stt" != "" ]; then
      messagePrint " ▪ TMC DeRegister Cluster"             "$TDH_TKGMC_NAME-$TDH_USER"
      kubectl config use-context ${TDH_TKGMC_NAME}-${TDH_USER}-admin@${TDH_TKGMC_NAME}-${TDH_USER}
      tmc managementcluster deregister $TDH_TKGMC_NAME-$TDH_USER -k $HOME/.kube/config  > /tmp/error.log 2>&1; ret=$?
      if [ $ret -ne 0 ]; then
        logMessages /tmp/error.log
        echo "ERROR: failed to deregister Management Cluster $TDH_TKGMC_NAME-$TDH_USER, please try manually"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/${TDH_TOOLS}.sh"
          echo "          tdh-tools:/$ tmc managementcluster deregister $TDH_TKGMC_NAME-$TDH_USER -k $HOME/.kube/config -f"
          echo "          tdh-tools:/$ tmc managementcluster delete $TDH_TKGMC_NAME-$TDH_USER -f"
          echo "          tdh-tools:/$ exit"
        else
          echo "       => tmc managementcluster deregister $TDH_TKGMC_NAME-$TDH_USER -k $HOME/.kube/config -f"
          echo "       => tmc managementcluster delete $TDH_TKGMC_NAME-$TDH_USER -f"
        fi

        exit 1
      fi
    fi
  fi

  # --- DELETE MANAGEMENT CLUSTER FROM THE JUMP HOST ---
  [ ! -d ~/.tanzu-demo-hub/config ] && mkdir -p ~/.tanzu-demo-hub/config
  CMDEXE="scripts/removeTKGmc.sh"
  CMDDIR="$SSH_HOME/tanzu-demo-hub"
  $SSH_TTY -n "[ -f $CMDDIR/$CMDEXE ] && cd $CMDDIR && $CMDEXE \"$TDH_TKGMC_NAME-$TDH_USER\" \"$DEBUG\" \"$TDH_TOOLS_CONTAINER_TYPE\" \"$DEPLOY_TKG_VERSION\""; ret=$?
  if [ ${ret} -ne 0 ]; then
    echo "ERROR: Failed to delete Management Server on $JUMP_HOST"
    echo "       => $SSH_DISPLAY -n tanzu-demo-hub/scripts/removeTKGmc.sh \"$TDH_TKGMC_NAME-$TDH_USER\" \"$DEBUG\" \"$TDH_TOOLS_CONTAINER_TYPE\" \"$DEPLOY_TKG_VERSION\""
    exit 1
  fi

  cnt=$(tanzu cluster list --include-management-cluster 2>/dev/null | grep -c " $TDH_TKGMC_NAME-$TDH_USER") 
  if [ $cnt -gt 0 ]; then 
    messageTitle "Deleting Management Cluster ($TDH_TKGMC_NAME-$TDH_USER)"
    tanzu management-cluster delete ${TDH_TKGMC_NAME}-$TDH_USER -y > /tmp/error.log 2>&1; ret=$?
    
    if [ $ret -ne 0 ]; then 
      logMessages /tmp/error.log
      echo "ERROR: failed to delete management cluster ($TDH_TKGMC_NAME-$TDH_USER)"
      if [ "$NATIVE" == "0" ]; then
        echo "    => tools/tdh-tools.sh"
        if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
          echo "       tdh-tools:/$ export AWS_REGION=$AWS_REGION"
        fi
        echo "       tdh-tools:/$ tanzu management-cluster delete $TDH_TKGMC_NAME-$TDH_USER -y"
        echo "       tdh-tools:/$ exit"
      else
        echo "    => tanzu management-cluster delete $TDH_TKGMC_NAME-$TDH_USER -y"
      fi
  
      exit 1
    fi

    [ -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.kubeconfig ] && rm -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.kubeconfig
    [ -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.cfg ] && rm -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.cfg
    [ -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.yaml ] && rm -f $HOME/.tanzu-demo-hub/config/$TDH_TKGMC_NAME-$TDH_USER.yaml
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    TERRAFORM_PATH=$HOME/.tanzu-demo-hub/terraform/aws
    if [ ! -d $TERRAFORM_PATH ]; then 
      mkdir -p $TERRAFORM_PATH
      cp -r ${TDHPATH}/terraform/aws $HOME/.tanzu-demo-hub/terraform
    fi

    TDH_TERRAFORM_TFVARS=$TERRAFORM_PATH/terraform_${TDH_TKGMC_ENVNAME}.tfvars
    TDH_TERRAFORM_TFSTATE=$TERRAFORM_PATH/terraform_${TDH_TKGMC_ENVNAME}.tfstate

    messageTitle "Deleting Jump Host (jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN})"
     
    cnt=0; ret=1
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
                          -var-file=$TDH_TERRAFORM_TFVARS -auto-approve > /tmp/error.log 2>&1; ret=$?
      [ $ret -eq 0 ] && break
      let cnt=cnt+1
      sleep 60
    done

    if [ $ret -ne 0 ]; then
      logMessages /tmp/error.log
      echo "ERROR: terraform destroy failed"
      if [ "$NATIVE" == "0" ]; then
        echo "    => tools/tdh-tools.sh"
        echo "       tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
        echo "                       -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
        echo "       tdh-tools:/$ exit"
      else
        echo "       => terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
        echo "                    -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
      fi

      exit 1
    fi
  fi

  cleanKubeconfig           $HOME/.kube/config
  cleanKubeconfig           $HOME/.kube-tkg/config
}

checkKeyPairs() {
  messageTitle "SSH Key Pairs"

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
    if [ ! -f ~/.tanzu-demo-hub/KeyPair-Azure.pem ]; then 
      # GENERATE INGRES FILES
      echo "remove and generate keypair"
      rm -f ~/.tanzu-demo-hub/KeyPair-Azure.pem ~/.tanzu-demo-hub/KeyPair-Azure.pub

      messagePrint " ▪ Generating Azure KeyPair" "~/.tanzu-demo-hub/KeyPair-Azure.pem"
      ssh-keygen -t rsa -b 4096 -f ~/.tanzu-demo-hub/KeyPair-Azure -P "" > /dev/null 2>&1
      mv ~/.tanzu-demo-hub/KeyPair-Azure ~/.tanzu-demo-hub/KeyPair-Azure.pem
      ls -l ~/.tanzu-demo-hub/KeyPair*
    else
      messagePrint " ▪ Azure KeyPair Verified" "~/.tanzu-demo-hub/KeyPair-Azure.pem"
    fi
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    SSH_KEY_NAME=tanzu-demo-hub
    SSH_KEY_FILE=$HOME/.tanzu-demo-hub/KeyPair-${SSH_KEY_NAME}-${AWS_REGION}.pem
    messagePrint " ▪ KeyPair Name" "$SSH_KEY_NAME"
    messagePrint " ▪ KeyPair File" "$SSH_KEY_FILE"

    # --- GENERATING KEY PAIR ---
    if [ ! -f $SSH_KEY_FILE ]; then 
      messagePrint " ▪ Generating AWS KeyPair" "SSH_KEY_FILE"
      aws ec2 --region=$AWS_REGION delete-key-pair --key-name $SSH_KEY_NAME > /dev/null 2>&1
      aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
         jq -r '.KeyMaterial' > $SSH_KEY_FILE
      chmod 600 $SSH_KEY_FILE
    else
      messagePrint " ▪ AWS KeyPair Verified" "SSH_KEY_FILE"
    fi

    if [ ! -d ~/.tanzu-demo-hub ] ; then mkdir ~/.tanzu-demo-hub; fi
  
    # --- VERIFY KEY-PAIR ---
    key=$(aws ec2 --region=$AWS_REGION describe-key-pairs | \
          jq -r --arg key "$SSH_KEY_NAME" '.KeyPairs[] | select(.KeyName == $key).KeyFingerprint')
  
    # --- CREATE ONE IF IT DOES NOT EXIST ---
    if [ "${key}" == "" ]; then 
      aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
         jq -r '.KeyMaterial' > $SSH_KEY_FILE
      chmod 600 $SSH_KEY_FILE
      key=$(aws ec2 --region=$AWS_REGION describe-key-pairs | \
            jq -r --arg key "$SSH_KEY_NAME" '.KeyPairs[] | select(.KeyName == $key).KeyFingerprint')
    fi

    if [ -f "${SSH_KEY_FILE}" ]; then
      # openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c
      # Linux: (stdin)= 60:db:70:2a:ce:0a:c1:ed:79:07:1c:be:9b:18:51:e9:78:84:7f:17
      # MAC:   60:db:70:2a:ce:0a:c1:ed:79:07:1c:be:9b:18:51:e9:78:84:7f:17
      if [ "$(uname)" == "Linux" ]; then 
        kfp=$(openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c | awk '{ print $2 }')
      else
        kfp=$(openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c)
      fi
    
      messagePrint " ▪ Verify KeyPair Fingerpring" "$kfp"
      if [ "${key}" != "${kfp}" ]; then
        messagePrint " ▪ KeyPair Fingerpring not valid, regenerating" "$SSH_KEY_NAME"
        aws ec2 --region=$AWS_REGION delete-key-pair --key-name $SSH_KEY_NAME > /dev/null
        aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
           jq -r '.KeyMaterial' > $SSH_KEY_FILE
        chmod 600 $SSH_KEY_FILE
      fi
    fi
  fi
}

configureLetsEnscript() {
  ##############################################################################################
  ################################ GENERATING TLS CERTIFICATES #################################
  ##############################################################################################

  CERTS_GENERATE_NEW=false
  domain="${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"

  if [ -d $HOME/.tanzu-demo-hub/certificates/$domain -a -f $HOME/.tanzu-demo-hub/certificates/$domain/privkey.pem ]; then
    $SSH_COMMAND -n "mkdir -p $SSH_HOME/tanzu-demo-hub/certificates"
    $SCP_COMMAND $HOME/.tanzu-demo-hub/certificates/$domain/* ${SSH_USER}@${SSH_HOST}:~/tanzu-demo-hub/certificates > /dev/null 2>&1
  fi

  CERTS_INSTALLED=$($SSH_COMMAND -n "[ -f ~/tanzu-demo-hub/certificates/privkey.pem ] && echo true || echo false")

  if [ "${CERTS_INSTALLED}" == "true" ]; then
    $SCP_COMMAND $HOME/.tanzu-demo-hub/certificates/$domain/* ${SSH_USER}@${SSH_HOST}:~/tanzu-demo-hub/certificates > /dev/null 2>&1

    CERTS_ENDDATE=$($SSH_COMMAND -n "openssl x509 -noout -in ~/tanzu-demo-hub/certificates/cert.pem -enddate | awk -F'=' '{ print \$2 }'")
    CERTS_EXPIRED=$($SSH_COMMAND -n "openssl x509 -noout -in ~/tanzu-demo-hub/certificates/cert.pem -checkend 3600 > /dev/null 2>&1; echo \$?")

    if [ $CERTS_EXPIRED -eq 0 ]; then
      messagePrint " ▪ Certificate Expiratation Data:" "$CERTS_ENDDATE"
    else
      messagePrint " ▪ Certificate Expiratation Data:" "$CERTS_ENDDATE [>>> *EXPIRED* <<<]"
      CERTS_GENERATE_NEW=true
    fi
  else
    CERTS_GENERATE_NEW=true
  fi

  if [ "${CERTS_GENERATE_NEW}" == "true" ]; then
    messagePrint " ▪ Generate new Certificate for Domain:" "$domain"
    route53createHostedZone $domain

    echo "-------------------------------------- GENERATE LET'S-ENCRYPT CERTIFICATES -------------------------------------"
    typ=$(echo $domain | egrep -c "aztkg|awstkg|gcptkg|vstkg")
    if [ $typ -ne 0 ]; then
      messageTitle "Generate Certificate for TKG Domains ($domain)"
      $SSH_COMMAND -n "sudo certbot certonly --dns-route53 -d '*.$domain' -m sadubois@pivotal.io --agree-tos -n --expand"
      if [ $? -ne 0 ]; then
        echo "ERROR: failed to generate certificate. There are probably to many cert requests happends and a limit reached"
        echo "       Try it again after some hours or search *.$domain in https://crt.sh/"
        exit 1
      fi
    fi

    # --- GET A COPY OF THE CERTIFICATES BACK ---
    [ ! -d $HOME/.tanzu-demo-hub/certificates/$domain ] && mkdir -p $HOME/.tanzu-demo-hub/certificates/$domain

    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live ] && sudo chmod -R a+r /etc/letsencrypt/live /etc/letsencrypt/archive"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live ] && sudo chmod 777 /etc/letsencrypt/live /etc/letsencrypt/live/$domain"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/archive ] && sudo chmod 777 /etc/letsencrypt/archive /etc/letsencrypt/archive/$domain"
    $SSH_COMMAND -n "[ ! -d $SSH_HOME/tanzu-demo-hub/certificates/$domain ] && mkdir -p $SSH_HOME/tanzu-demo-hub/certificates"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live/$domain ] && cp /etc/letsencrypt/live/$domain/* ~/tanzu-demo-hub/certificates"

    messageTitle " Copy new certificates from jump to local ./certificates/$domain"
    cnt=0; ret=1
    while [ ! -f ./certificates/$domain/fullchain.pem ]; do
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ > /dev/null 2>&1; ret=$?
      [ $cnt -gt 5 ] && break

      sleep 10
      let cnt=cnt+1
    done

    if [ $ret -ne 0 ]; then 
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ 
      echo "ERROR: failed to copy SSL/TLS cert from jumphost"
      echo "       => SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ "
      exit
    fi

    echo "----------------------------------------------------------------------------------------------------------------"
  fi
}

createJumpHost() {
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    JUMP_HOST="jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"
    messageTitle "AWS Jump-Server ($JUMP_HOST)"

    TERRAFORM_PATH=$HOME/.tanzu-demo-hub/terraform/aws
    if [ ! -d $TERRAFORM_PATH ]; then
      mkdir -p $TERRAFORM_PATH
    fi

    cp -r ${TDHPATH}/terraform/aws $HOME/.tanzu-demo-hub/terraform
    cd $TERRAFORM_PATH && git clone https://github.com/terraform-aws-modules/terraform-aws-ec2-instance.git > /dev/null 2>&1

    TDH_TERRAFORM_TFVARS=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.tfvars
    TDH_TERRAFORM_TFSTATE=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.tfstate
    TDH_TERRAFORM_STATE=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.state
    KEY_NAME=tanzu-demo-hub

    ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
         Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)
    if [ "${ins}" == "" ]; then
      messagePrint " ▪ Cleaning up leftover terraform deployments" "${TERRAFORM_PATH}"
      echo "aws_region = \"$AWS_REGION\""                          >  $TDH_TERRAFORM_TFVARS
      echo "owner = \"tdh-$TDH_TKGMC_ENVNAME\""                    >> $TDH_TERRAFORM_TFVARS
      echo "aws_region_az = \"$az\""                               >> $TDH_TERRAFORM_TFVARS
      echo "key_pair = \"$KEY_NAME\""                              >> $TDH_TERRAFORM_TFVARS

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]
      then
	if [ -f $TDH_TERRAFORM_TFSTATE ]
	then
	  if [ $DEBUG -gt 0 ]; then
	    echo "--------------------------------------------------------------------------------------------------------------"
	    terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
		      -var-file=$TDH_TERRAFORM_TFVARS -auto-approve; ret=$? 
	    echo "--------------------------------------------------------------------------------------------------------------"
	  else
	    terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
		      -var-file=$TDH_TERRAFORM_TFVARS -auto-approve > /dev/null 2>&1; ret=$? 
	  fi

	  if [ $ret -ne 0 ]; then
	    echo "ERROR: terraform destroy failed"
            if [ "$NATIVE" == "0" ]; then
              echo "       => tools/tdh-tools.sh"
              echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
	      echo "                                 -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
              echo "          tdh-tools:/$ exit"
            else
	      echo "       => terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
	      echo "                    -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
            fi
	    exit
	  fi
	fi
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi

      #aws ec2 --region=$AWS_REGION describe-key-pairs --key-names ${KEY_NAME} > /dev/null 2>&1; ret=$?
      #if [ $ret -ne 0 ]; then
      #  messagePrint " ▪ Creating Key Pair" "${KEY_NAME}"
      #  aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME} \
      #        --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem 2>/dev/null
      #  chmod 600 ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem
      #  if [ $? -ne 0 ]; then
      #    echo "ERROR: Creating Key Pairs failed"
      #    if [ "$NATIVE" == "0" ]; then
      #      echo "       => tools/tdh-tools.sh"
      #      echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME}  \\"
      #      echo "                         --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem"
      #      echo "          tdh-tools:/$ exit"
      #    else
      #      echo "       => aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME}  \\"
      #      echo "                  --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem"
      #    fi
      #
      #    exit 1
      #  fi
      #else
      #  messagePrint " ▪ Key Pair exists on AWS" "${KEY_NAME}"
      #fi

      messagePrint " ▪ Deploy vSphere Jump-Server with (terraforms)" "$JUMP_HOST"
      messagePrint " ▪ Creating Variable file" "${TERRAFORM_PATH}/terraform.tfvars"

      availability_zone=$(echo $AWS_PRIMARY_AZ | sed 's/^.*\(.\)$/\1/g') 
      if [ "$availability_zone" != "a" -a "$availability_zone" != "b" -a "$availability_zone" != "c" ]; then 
        echo "ERROR: Availability Zone of an AWS Region should be 'a', 'b' or 'c'"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/tdh-tools.sh"
          echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION describe-availability-zones --output text"
          echo "          tdh-tools:/$ exit"
        else
          echo "       => aws ec2 --region=$AWS_REGION describe-availability-zones --output text"
        fi

        exit 1
      fi

      echo "aws_region = \"$AWS_REGION\""                          >  $TDH_TERRAFORM_TFVARS
      echo "owner = \"tdh-$TDH_TKGMC_ENVNAME\""                    >> $TDH_TERRAFORM_TFVARS
      echo "aws_region_az = \"$availability_zone\""                >> $TDH_TERRAFORM_TFVARS
      echo "key_pair = \"$KEY_NAME\""                              >> $TDH_TERRAFORM_TFVARS

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]; then
        if [ $DEBUG -gt 0 ]; then 
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} init"
          echo "--------------------------------------------------------------------------------------------------------------"
          terraform -chdir=${TERRAFORM_PATH} init; ret=$?
        else
          messagePrint " ▪ Terraform (init)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} init > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then 
          echo "ERROR: terraform init failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/tdh-tools.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} init"
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} init"
          fi
          exit
        fi

        if [ $DEBUG -gt 0 ]; then
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out jump -state=$TDH_TERRAFORM_TFSTATE"
          echo "--------------------------------------------------------------------------------------------------------------"
          terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE; ret=$?
        else
          messagePrint " ▪ Terraform (plan)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then 
          echo "ERROR: terraform plan failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/tdh-tools.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \\"
            echo "                         -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE"
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \\"
            echo "                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE"
          fi

          exit 1
        fi

        if [ $DEBUG -gt 0 ]; then
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
          terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE "jump-$TDH_TKGMC_ENVNAME"; ret=$?
        else
          messagePrint " ▪ Terraform (apply)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE "jump-$TDH_TKGMC_ENVNAME" > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then
          echo "1ERROR: terraform apply failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/tdh-tools.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
          fi

          exit 1
        fi

        #terraform -chdir=$TERRAFORM_PATH destroy -state=$TDH_TERRAFORM_TFSTATE -var-file=$TDH_TERRAFORM_TFVARS -auto-approve
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi

      # --- WAIT FOR INSTANCE TO COME ONLINE ---
      ins=""; cnt=0
      while [ "$ins" == "" -a $cnt -lt 5 ]; do
        ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
           Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)

        sleep 20
        let cnt=cnt+1
      done

      if [ "$ins" == "" ]; then 
        echo "ERROR: Failed to get Instance ID of new crewated Jump VM"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/tdh-tools.sh"
          echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION describe-instances \\"
          echo "                               --filters \"Name=instance-state-name,Values=pending,running,stopped\" \\"
          echo "                               Name=tag:Owner,Values=\"tdh-${TDH_TKGMC_ENVNAME}\""
          echo "          tdh-tools:/$ exit"
        else
          echo "       => aws ec2 --region=$AWS_REGION describe-instances \\"
          echo "                  --filters \"Name=instance-state-name,Values=pending,running,stopped\" \\"
          echo "                  Name=tag:Owner,Values=\"tdh-${TDH_TKGMC_ENVNAME}\""
        fi

        exit 1
      fi

      stt=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].State.Name")
      dns=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].PublicDnsName")
      pip=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].PublicIpAddress")

      ZONE_ID=$(aws route53 list-hosted-zones-by-name --dns-name ${AWS_HOSTED_DNS_DOMAIN} | jq -r '.HostedZones[0].Id')
      ZONE_ID_STR=$(echo "${ZONE_ID}" | awk -F'/' '{ print $NF }')
      messagePrint " ▪ DNS Zone (${AWS_HOSTED_DNS_DOMAIN}:" "zone managed by route53"
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"

      # --- CREATE HOSTED ZONE ---
      route53createHostedZone $TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN

      # --- UPDATE DNS DOMAIN ---
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"
      route53setDNSrecord "$pip" "$JUMP_HOST" "$AWS_HOSTED_DNS_DOMAIN"

      messagePrint " ▪ Updating Zone Record for (jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN)" "$pip"
      route53setDNSrecord "$pip" "jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN" "$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN"
    fi

    ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
       Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)
    stt=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].State.Name")
    dns=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].PublicDnsName")
    pip=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].PublicIpAddress")

    messageTitle "Verify AWS Jump-Server"
    messagePrint " ▪ AWS Instance ID" "$ins"
    messagePrint " ▪ Jump Server Hostname" "$JUMP_HOST"
    messagePrint " ▪ Jump Server Status" "$stt"
    messagePrint " ▪ Jump Server IP Address" "$pip"
    messagePrint " ▪ Destroy Command" "terraform destroy"

    messageLine
    echo "terraform -chdir=$TERRAFORM_PATH destroy \\"
    echo "          -state=$TDH_TERRAFORM_TFSTATE \\"
    echo "          -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
    messageLine

    [ -s ~/.ssh/known_hosts ] && sed -in "/$JUMP_HOST/d" ~/.ssh/known_hosts
    SSH_USER=ubuntu
    SSH_HOME=/home/ubuntu
    SSH_HOST=$JUMP_HOST
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=30"
    SCP_OPTIONS="-o StrictHostKeyChecking=no"
    SSH_COMMAND="ssh -tt -q $SSH_OPTIONS -i ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem ${SSH_USER}@${SSH_HOST}"
    SCP_COMMAND="scp -r $SCP_OPTIONS -i ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem"

    messagePrint " ▪ Wait for SSH to be ready" "< 5m"
    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" -a "$TDH_TKGMC_CREATE_JUMPHOST" == "false" ]; then
    JUMP_HOST="${VSPHERE_JUMPHOST_NAME}"
    SSH_USER="${VSPHERE_JUMPHOST_USER}"
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=240"
    SSH_PRIVATE_KEY=$VSPHERE_SSH_PRIVATE_KEY_FILE
    SSH_COMMAND="ssh -tt -q $SSH_OPTIONS -i ${SSH_PRIVATE_KEY} ${SSH_USER}@${JUMP_HOST}"

    messageTitle "Verify vSphere Jump-Server ($JUMP_HOST)"
    messagePrint " ▪ Wait for SSH to be ready" "< 3m"

    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done

    messageTitle "Verify SuDO Access" "$JUMP_HOST"
    verify_datacenter
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" -a "$TDH_TKGMC_CREATE_JUMPHOST" == "true" ]; then
    VSPHERE_JUMPHOST_NAME=jump.$VSPHERE_DNS_DOMAIN

    JUMP_HOST="${VSPHERE_JUMPHOST_NAME}"
    SSH_USER=ubuntu
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=240"
    SSH_PRIVATE_KEY=$VSPHERE_SSH_PRIVATE_KEY_FILE
    SSH_COMMAND="ssh -tt -q $SSH_OPTIONS -i ${SSH_PRIVATE_KEY} ${SSH_USER}@${JUMP_HOST}"
    SSH_USER=ubuntu

    # --- TEST IF JUMP HOST IS ALREADY DEPLOYED
    $SSH_COMMAND -n "hostname > /dev/null 2>&1"; ret=$?
    if [ "$ret" != 0 ]; then   
      # --- PACKER CREATE JUMP TEMPLATE ---
      messageTitle "Crreate vSphere Jump-Server ($JUMP_HOST) with (packer)"
      messagePrint " ▪ Using Ubuntu Packer Config" "${TDHPATH}/packer/ubuntu.json"
      messagePrint " ▪ Generating Packer Config" "/tmp/jump.json"

      verify_datacenter 

      cat ${TDHPATH}/packer/jump_variables.json | sed -e "s/XXX_VSPHERE_SERVER_XXX/$VSPHERE_VCENTER_SERVER/g" \
         -e "s/XXX_VSPHERE_PASSWORD_XXX/$VSPHERE_VCENTER_PASSWORD/g"  -e "s/XXX_VSPHERE_DATACENTER_XXX/$VSPHERE_DATACENTER/g" \
         -e "s/XXX_VSPHERE_ADMIN_XXX/$VSPHERE_VCENTER_ADMIN/g"  -e "s/XXX_VSPHERE_DATACENTER_XXX/$VSPHERE_DATACENTER/g" \
         -e "s/XXX_VSPHERE_DATASTORE_XXX/$VSPHERE_DATASTORE/g" -e "s/XXX_VSPHERE_CLUSTER_XXX/$VSPHERE_CLUSTER/g"\
         -e "s/XXX_VSPHERE_WAN_NETWORK_XXX/$VSPHERE_WAN_NETWORK/g" \
         -e "s/XXX_VSPHERE_MANAGEMENT_NETWORK_XXX/$VSPHERE_NETWORK/g" > /tmp/jump.json

      messagePrint " ▪ Generating Preseed Config" "/tmp/preseed.cfg"
      VSPHERE_SSH_PUBLIC_KEY=$(cat $VSPHERE_SSH_PUBLIC_KEY_FILE)
      echo "    in-target /bin/sh -c \"echo '$VSPHERE_SSH_PUBLIC_KEY' >> /home/ubuntu/.ssh/authorized_keys\"; " > /tmp/snipset.txt
      cat ${TDHPATH}/packer/jump_preseed.cfg | sed -e '/XXX_SSHKEY_XXX/r /tmp/snipset.txt' -e '/XXX_SSHKEY_XXX/d' > /tmp/preseed.cfg

      if [ -x /usr/local/bin/packer ]; then
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> packer build -var-file=/tmp/jump.json ${TDHPATH}/packer/ubuntu.json"
        echo "--------------------------------------------------------------------------------------------------------------"
        packer build -var-file=/tmp/jump.json ${TDHPATH}/packer/ubuntu.json | sed '/^$/d'
        echo "--------------------------------------------------------------------------------------------------------------"
      else
        echo "ERROR: HashiCorp Packer has not been installed, download it from https://www.packer.io/downloads" 
        echo "       and install it in /usr/local/bin/packer"; exit 0
      fi

      messagePrint "Deploy vSphere Jump-Server with (terraforms)" "$JUMP_HOST"
      messagePrint " ▪ Creating Variable file" "/tmp/terraform.tfvars"
      echo "vsphere_user = \"$VSPHERE_VCENTER_ADMIN\""             >  /tmp/terraform.tfvars
      echo "vsphere_password = \"$VSPHERE_VCENTER_PASSWORD\""      >> /tmp/terraform.tfvars
      echo "vsphere_server = \"$VSPHERE_SERVER\""                  >> /tmp/terraform.tfvars
      echo "vsphere_datacenter = \"$VSPHERE_DATACENTER\""          >> /tmp/terraform.tfvars
      echo "vsphere_datastore = \"$VSPHERE_DATASTORE\""            >> /tmp/terraform.tfvars
      echo "vsphere_compute_cluster = \"$VSPHERE_CLUSTER\""        >> /tmp/terraform.tfvars
      echo "#vsphere_resource_pool = \"cluster/Resources\""        >> /tmp/terraform.tfvars
      echo "vsphere_network = \"$VSPHERE_NETWORK\""                >> /tmp/terraform.tfvars
      echo "vsphere_virtual_machine_template = \"jump_template\""  >> /tmp/terraform.tfvars
      echo "vsphere_virtual_machine_name = \"jump\""               >> /tmp/terraform.tfvars
      echo "root_password = \"root\""                              >> /tmp/terraform.tfvars

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]; then
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TERRAFORM_PATH} init"
        echo "--------------------------------------------------------------------------------------------------------------"
        terraform -chdir=${TERRAFORM_PATH} init
  
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TDHPATH}/terraform plan -var-file=/tmp/terraform.tfvars -out jump -state=/tmp/terraform.state"
        echo "--------------------------------------------------------------------------------------------------------------"
        terraform -chdir=${TERRAFORM_PATH} plan -var-file=/tmp/terraform.tfvars -out jump -state=/tmp/terraform.state
  
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TERRAFORM_PATH} apply -state=/tmp/terraform.tfstate \"jump\""
        terraform -chdir=${TERRAFORM_PATH} apply -state=/tmp/terraform.tfstate "jump"
  
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi
    else
      messagePrint "Verify vSphere Jump-Server" "$JUMP_HOST"
    fi

    messagePrint " ▪ Wait for SSH to be ready" "< 3m"
    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
    JUMP_HOST="jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"

    # --- VERIFY AZURE ACCESS ---
    az ad app list > /dev/null 2>&1
    if [ $? -ne 0 ]; then 
      echo "ERROR: Failed to list Microsoft Azure Applications, please try manually"
      echo "       => az ad app list"
      exit
    fi

    # --- VERIFY / CREATE APPLICATION ID AND SERVICE PRINCIPLE ---
    appid=$(az ad app list --display-name "TanzuDemoHub-$TDH_USER" 2>/dev/null | jq -r '.[].appId')
    if [ "$appid" == "" ]; then 
      messageTitle "Register Azure Application (TanzuDemoHub-$TDH_USER)"
      az ad sp create-for-rbac --role Owner --name "TanzuDemoHub-$TDH_USER" > /tmp/TanzuDemoHub-$TDH_USER.json 2>/dev/null
      AZURE_CLIENT_ID=$(jq -r '.appId' /tmp/TanzuDemoHub-$TDH_USER.json)
      AZURE_CLIENT_SECRET=$(jq -r '.password' /tmp/TanzuDemoHub-$TDH_USER.json)

      echo "INFO: Please set the new generated Azure Client Secret for the Azure ClientID (TanzuDemoHub-$TDH_USER)"
      echo "      into your ~/.tanzu-demo-hub.cfg and restart $0"
      echo "      => export AZURE_CLIENT_ID=\"$AZURE_CLIENT_ID\""
      echo "      => export AZURE_CLIENT_SECRET=\"$AZURE_CLIENT_SECRET\""
      echo " "
      exit 0
    else
      if [ "$AZURE_CLIENT_SECRET" == "" ]; then 
        AZURE_CLIENT_ID=$appid
        AZURE_CLIENT_SECRET=$(az ad sp create-for-rbac --role Owner --name "TanzuDemoHub-$TDH_USER)" 2>/dev/null | jq -r '.password') 
        echo "INFO: Please set the new generated Azure Client Secret for the Azure ClientID (TanzuDemoHub-$TDH_USER)"
        echo "      into your ~/.tanzu-demo-hub.cfg and restart $0"
        echo "      => export AZURE_CLIENT_SECRET=\"$AZURE_CLIENT_SECRET\""
        echo " "
        exit 0
      else
        docker run --rm --name azure-cli bitnami/azure-cli:latest login --service-principal --username $appid --password $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID > /dev/null 2>&1
        if [ $? -ne 0 ]; then 
          AZURE_CLIENT_ID=$appid
          AZURE_CLIENT_SECRET=$(az ad sp create-for-rbac --name "TanzuDemoHub-$TDH_USER)" 2>/dev/null | jq -r '.password')
          echo "INFO: The configured Azure Client Secret seams to be wrong or outdated, please set"
          echo "      the new generated Azure Client Secret for the Azure ClientID (TanzuDemoHub-$TDH_USER)"
          echo "      into your ~/.tanzu-demo-hub.cfg and restart $0"
          echo "      => export AZURE_CLIENT_SECRET=\"$AZURE_CLIENT_SECRET\""
          echo " "
          exit 0
        fi
      fi
    fi

    appid=$(az ad app list --display-name "TanzuDemoHub-$TDH_USER" 2>/dev/null | jq -r '.[].appId')
    objid=$(az ad sp list --all --display-name TanzuDemoHub-$TDH_USER 2>/dev/null | jq -r '.[].objectId')
    messageTitle "Verify Azure Application (TanzuDemoHub-$TDH_USER)"
    messagePrint " ▪ Azure Client ID" "$appid"
    messagePrint " ▪ Azure Client Secret" "verified"
    messagePrint " ▪ Application Display Name" "TanzuDemoHub-$TDH_USER"
    messagePrint " ▪ ServicePrincipal" "$objid"
    messagePrint " ▪ Role Binding" "Owner"

    messageTitle "Verifing Azure Jump-Server ($JUMP_HOST)"
    stt=$(az group exists --name Admin)
    if [ "$stt" == "false" ]; then
      messagePrint " ▪ Creating Azure Ressource Group" "Admin"
      az group create --name Admin --location $AZURE_LOCATION > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Creating Ressource Group Admin"
        echo "       => az group create --name Admin --location $AZURE_LOCATION"
        exit 1
      fi
    fi
  
    vm_stt=$(az vm list -d --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].powerState')
    if [ "${vm_stt}" == "" ]; then
      # --- VM DOES NOT EXIST, CREATING ---
      nam=$(az network vnet list -g Admin --query "[?contains(name, 'admin-vnet')]" | jq -r '.[].name')
      if [ "$nam" != "admin-vnet" ]; then
        messagePrint " ▪ Creating Vnet" "admin-vnet"

        az network vnet create \
            --resource-group Admin \
            --name admin-vnet \
            --address-prefix 192.168.0.0/16 \
            --subnet-name AdminSubnet \
            --subnet-prefix 192.168.1.0/24 > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Vnet admin-vnet"
          exit 1
        fi
      else
        messagePrint " ▪ Verify Vnet" "admin-vnet"
      fi

      nam=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | jq -r '.[].name')
      if [ "$nam" != "AdminPublicIP_$TDH_TKGMC_ENVNAME" ]; then
        messagePrint " ▪ Creating PublicIP" "AdminPublicIP_$TDH_TKGMC_ENVNAME"

        az network public-ip create \
            --resource-group Admin \
            --name AdminPublicIP_$TDH_TKGMC_ENVNAME  > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating PublicIP AdminPublicIP_$TDH_TKGMC_ENVNAME"
          exit 1
        fi
      else
        pip=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | jq -r '.[].ipAddress')

        messagePrint " ▪ Verify PublicIP (AdminPublicIP_$TDH_TKGMC_ENVNAME)" "$pip"
      fi

      nam=$(az network nsg list --query "[?contains(name, 'AdminSG')]" | jq -r '.[].name')
      if [ "$nam" != "AdminSG" ]; then
        messagePrint " ▪ Creating Security Group" "AdminSG"

        az network nsg create \
            --resource-group Admin \
            --name AdminSG > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group AdminSG"
          exit 1
        fi
      else
        messagePrint " ▪ Verify Security Group" "AdminSG"
      fi

      nam=$(az network nsg rule list -g Admin --nsg-name AdminSG --query "[?contains(name, 'AdminSG-RuleSSH')]" | \
            jq -r '.[].name')
      if [ "$nam" != "AdminSG-RuleSSH" ]; then
        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleSSH (22)"

        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleSSH \
            --protocol tcp \
            --priority 1000 \
            --destination-port-range 22 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleSSH"
          exit 1
        fi

        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleLDAP (636/389)"
        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleLDAP \
            --priority 1001 \
            --destination-port-range 636 389 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleLDAP (tcp/636)"
          exit 1
        fi

        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleHTTP (80,443)"
        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleHTTP \
            --priority 1002 \
            --destination-port-range 80 443 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleLDAP (tcp/636)"
          exit 1
        fi

      else
        messagePrint " ▪ Verify Security Group Rule" "AdminSG-RuleSSH"
      fi

      nam=$(az network nic list -g Admin --query "[?contains(name, 'AdminNic_$TDH_TKGMC_ENVNAME')]" | \
            jq -r '.[].name')
      if [ "$nam" != "AdminNic_$TDH_TKGMC_ENVNAME" ]; then
        messagePrint " ▪ Creating Nic" "AdminNic_$TDH_TKGMC_ENVNAME"

        az network nic create \
            --resource-group Admin \
            --name AdminNic_$TDH_TKGMC_ENVNAME \
            --vnet-name admin-vnet \
            --subnet AdminSubnet \
            --public-ip-address AdminPublicIP_$TDH_TKGMC_ENVNAME \
            --network-security-group AdminSG > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating NIC AdminNic_$TDH_TKGMC_ENVNAME"
          echo "       => az network nic create --resource-group Admin --name AdminNic_$TDH_TKGMC_ENVNAME \\"
          echo "            --vnet-name admin-vnet --subnet AdminSubnet --public-ip-address AdminPublicIP_$TDH_TKGMC_ENVNAME "
          exit 1
        fi
      else
        messagePrint " ▪ Verify NIC" "AdminNic_$TDH_TKGMC_ENVNAME"
      fi

      #nam=$(az vm list --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].name')
      #if [ "$nam" != "$JUMP_HOST" ]; then
      messagePrint " ▪ Creating VM" "$JUMP_HOST"

      az vm create \
          --resource-group Admin \
          --name $JUMP_HOST \
          --location $AZURE_LOCATION \
          --nics AdminNic_$TDH_TKGMC_ENVNAME \
          --image UbuntuLTS \
          --admin-username ubuntu \
          --size Standard_DS2_v2 \
          --os-disk-size-gb 100 \
          --ssh-key-values ~/.tanzu-demo-hub/KeyPair-Azure.pub > /dev/null 2>&1
          #--generate-ssh-keys > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Creating VM"
        echo "       => az vm create --resource-group Admin --name $JUMP_HOST --location $AZURE_LOCATION \\"
        echo "          --nics AdminNic_$TDH_TKGMC_ENVNAME --image UbuntuLTS --admin-username ubuntu --generate-ssh-keys"
        exit 1
      fi
    else
      #stt=$(az vm list -d --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].powerState')
      if [ "${vm_stt}" != "VM running" ]; then
        messagePrint " ▪ Starting VM" "$JUMP_HOST"
        az vm start --resource-group Admin --name $JUMP_HOST
      fi
    fi

    pip=""
    while [ "$pip" == "" -o "$pip" == "null" ]; do
      pip=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | \
            jq -r '.[].ipAddress')
      sleep 10
    done

    aip=$(route53getIPaddress $TDH_TKGMC_ENVNAME $AWS_HOSTED_DNS_DOMAIN)

    # --- UPDATE DNS DOMAIN ---
    if [ "${pip}" != "${aip}" ]; then
      messagePrint " ▪ DNS Zone (${AWS_HOSTED_DNS_DOMAIN})" "zone managed by route53"
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"
      route53setDNSrecord "$pip" "$JUMP_HOST" "$AWS_HOSTED_DNS_DOMAIN"
      messagePrint " ▪ Updating Zone Record for (jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN)" "$pip"
      route53setDNSrecord "$pip" "jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN" "$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN"

      [ -s ~/.ssh/known_hosts ] && sed -in "/$JUMP_HOST/d" ~/.ssh/known_hosts
      messagePrint " ▪ Wait for SSH Daemon on jump-host to come online" "< 5min"
    fi
  fi
}

# --- VERYFY ACCESS TO CLOUD ---
checkTDHenvironment

# --- VERIFY TOOLS AND ACCESS ---
checkCloudCLI
checkCLIcommands TOOLS
checkCLIcommands TKG
checkCLIcommands TANZU
checkCLIcommands TMC
checkCLIcommands VSPHERE

# --- INSTALL TANZU PLUGINS ---
installTanzuPlugins

# --- CLEANUP KUNECONFIG ---
cleanKubeconfig
checkTDHAccess
checkCloudAccess

#checkTMCAccess
checkKeyPairs
#checkTKGdownloads
tmcCheckLogin
checkIdentityProvider

# --- CREATE TKG CLUSTER AND JUMP SERVER
createJumpHost
sshEnvironment

configureJumpHost
buildTDHToolsContainer   $TDH_TOOLS_CONTAINER_TYPE
configureLetsEnscript

# --- SET MANAGEMENT CLUSTER NAME ---
TDH_TKGMC_NAME=${TDH_TKGMC_NAME}-${TDH_USER}

if [ "$DEPLOY_TKG_CLEAN" -eq 1 ]; then
  deleteManagementCluster $TDH_TKGMC_NAME
  cleanupEnvironment
  cleanKubeconfig
  cleanManagementCluster

  # --- CLEAN CONFIG ON JUMP HOST ---
  $SSH_COMMAND -n "rm -f $SSH_HOME/.kube/config $SSH_HOME/.kube-tkg/config $SSH_HOME/.config/tanzu/config.yaml"

  exit 0
fi

# --- UPLOAD OVA IMAGES TO VCENTER ---
if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" -a "${TDH_TKGMC_TKG_TYPE}" == "tkgs" ]; then
  #########################################################################################################################
  ######################################## TANZU KUBERNETS GRID FOR VPSHERE (TKGs) ########################################
  #########################################################################################################################

  messageTitle "Login to vSphere Supervicer Cluster"
  messagePrint " ▪ vSphere Supervisor Cluster API"        "$VSPHERE_API_SERVER"
  messagePrint " ▪ vSphere Supervisor Cluster User"       "$VSPHERE_VCENTER_ADMIN"
  messagePrint " ▪ vSphere Supervisor Cluster Password"   "$(maskPassword \"$VSPHERE_VCENTER_PASSWORD\")"
  messagePrint " ▪ Kubernetes Context"                    "wcp.$VSPHERE_DNS_DOMAIN"
  KUBECTL_VSPHERE_PASSWORD=$VSPHERE_VCENTER_PASSWORD kubectl vsphere login \
    --insecure-skip-tls-verify --server $VSPHERE_API_SERVER -u administrator@vsphere.local > /dev/null 2>&1
  if [ $? -ne 0 ]; then
    echo "ERROR: Failed to login to vSphere Supervicer Cluster ($VSPHERE_API_SERVER)"
    echo "       Please try manually"
    echo "       => export KUBECTL_VSPHERE_PASSWORD=$VSPHERE_VCENTER_PASSWORD"
    echo "       => kubectl vsphere login --insecure-skip-tls-verify --server $VSPHERE_API_SERVER -u $VSPHERE_VCENTER_ADMIN"
    exit
  fi

  kubectl config use-context $wcp.$VSPHERE_DNS_DOMAIN > /dev/null 2>&1
  messageLine
  kubectl config get-contexts
  messageLine

  # --- CLEANUP OLD SERVER CONFIG ---
  cnt=$(tanzu config server list | egrep -c " $TDH_TKGMC_NAME ") 
  if [ $cnt -gt 0 ]; then 
    tanzu config server delete $TDH_TKGMC_NAME -y > /dev/null 2>&1
    if [ $? -ne 0 ]; then
      echo "ERROR: Failed to delete server $TDH_TKGMC_NAME"
      echo "       => tanzu config server delete $TDH_TKGMC_NAME"
      exit
    fi
  fi

  tanzu login --name $TDH_TKGMC_NAME --kubeconfig ~/.kube/config --context wcp.$VSPHERE_DNS_DOMAIN > /dev/null 2>&1
  if [ $? -ne 0 ]; then
    echo "ERROR: Failed to login to vSphere Supervicer Cluster ($VSPHERE_API_SERVER)"
    echo "       Please try manually"
    echo "       => tanzu login --name $TDH_TKGMC_NAME --kubeconfig ~/.kube/config --context wcp.$VSPHERE_DNS_DOMAIN"
    exit
  fi

  tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1
  if [ $? -ne 0 ]; then
    messageTitle "Configure vSphere Supervicer Cluster as TMC Management Cluster"
    messagePrint " ▪ TMC Register Cluster"             "$TDH_TKGMC_NAME"

    ret=1; cnt=0
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -k $KUBECONFIG -p TKGS -o /tmp/k8s-register-manifest.yaml >/dev/null 2>&1; ret=$?
      [ $ret -eq 0 ] && break
      sleep 30
      let cnt=cnt+1
    done

    if [ $? -ne 0 ]; then
      echo "ERROR: failed to register TKG Management Cluster: $TDH_TKGMC_NAME to TMC"
      echo "       => tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -o /tmp/k8s-register-manifest.yaml"
      exit
    fi

    TMC_MGMT_NS=$(kubectl get ns | egrep "^svc-tmc" | awk '{ print $1 }')
    gsed -i "s/  namespace:.*$/  namespace: $TMC_MGMT_NS/g" /tmp/k8s-register-manifest.yaml

    messagePrint " ▪ Install TMC Agent in Namespace"             "vmware-system-tmc"
    ret=1; cnt=0
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      kubectl apply -f /tmp/k8s-register-manifest.yaml > /tmp/log 2>&1; ret=$?
      [ $ret -eq 0 ] && break
      sleep 30
      let cnt=cnt+1
    done

    if [ $ret -ne 0 ]; then
      echo "ERROR: failed to install TMC Agent"
      echo "       => kubectl apply -f /tmp/k8s-register-manifest.yaml"
      messageLine; cat /tmp/log; messageLine
      exit
    fi

    cnt=0; stt="PENDING"
    while [ "$stt" != "READY" -a $cnt -lt 10 ]; do
      stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.phase')
      sleep 60
  
      let cnt=cnt+1
    done
  fi

  #govc ls /Pacific-Datacenter/vm/Namespaces
  #govc storage.policy.ls
  if [ "$(vsNanespaceExists tanzu-demo-hub)" != "true" ]; then 
    messageTitle "Create vSphere Naamespace (tanzu-demo-hub)"
    messagePrint " ▪ vSphere Namespace Name"          "tanzu-demo-hub"
    messagePrint " ▪ vSphere Namespace Permission"    "sadubois"
    messagePrint " ▪ vSphere Storage Polocy"          "pacific-gold-storage-policy"
    vsNamespaceCreate tanzu-demo-hub pacific-gold-storage-policy sadubois
  fi

  messageTitle "Verify vSphere Naamespace (tanzu-demo-hub)"
  messagePrint " ▪ vSphere Namespace Name"          "tanzu-demo-hub"
  messagePrint " ▪ vSphere Namespace Permission"    "sadubois"
  messagePrint " ▪ vSphere Storage Polocy"          "pacific-gold-storage-policy"
  if [ $DEBUG -gt 0 ]; then 
    messageLine
    vsNamespaceGet tanzu-demo-hub
    messageLine
  fi

  messageTitle "Verify TMC Management Cluster"
  messagePrint " ▪ TMC Register Cluster"             "$TDH_TKGMC_NAME"
  if [ $DEBUG -gt 0 ]; then
    messageLine
    tmc managementcluster get $TDH_TKGMC_NAME
    messageLine
  else
    stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.phase')
    msg=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.message')
    messagePrint " ▪ TMC Register Cluster Status"             "$stt"
    if [ "$stt" != "READY" ]; then
      messageLine
      echo $msg
      messageLine
    fi
  fi

  mkdir -p $HOME/.tanzu-demo-hub/config
  TMC_DEPLOMENT_CONFIG=$HOME/.tanzu-demo-hub/config/tmc-vsphere-$TDH_USER.cfg
  echo "# ----------------------------------------------------------------------------------------------------" >  $TMC_DEPLOMENT_CONFIG
  echo "# TDH Configuration Utility - TKG Deployment Config"                                                    >> $TMC_DEPLOMENT_CONFIG
  echo "# ----------------------------------------------------------------------------------------------------" >> $TMC_DEPLOMENT_CONFIG
  echo "# 2020-10-16 sdubois  AWS TKG Cluster"                                                                  >> $TMC_DEPLOMENT_CONFIG
  echo "# ----------------------------------------------------------------------------------------------------" >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_INFRASTRUCTURE=tmc"                                                                                 >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_ENVNAME=vstkg"                                                                                      >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_DEPLOYMENT_CLOUD=vSphere"                                                                           >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGMC_TKG_TYPE=tkgs"                                                                                >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_MANAGEMENT_CLUSTER=$TDH_TKGMC_NAME"                                                                 >> $TMC_DEPLOMENT_CONFIG
  echo "TMC_TKGWC_TEMPLATE=default    # "default" = 1 control plane node; "aws-ha" = 3 control plane nodes"     >> $TMC_DEPLOMENT_CONFIG
  echo "#TDH_TKGWC_CONTROPLANE_TYPE=best-effort-small"                                                          >> $TMC_DEPLOMENT_CONFIG
  echo "#TDH_TKGWC_WORKERNODES_TYPE=best-effort-small"                                                          >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGWC_CONTROPLANE_TYPE=guaranteed-small"                                                            >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGWC_WORKERNODES_TYPE=guaranteed-small"                                                            >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGWC_STORAGE_CLASS=pacific-gold-storage-policy"                                                    >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGMC_SERVICE_CIDR=172.20.0.0/16"                                                                   >> $TMC_DEPLOMENT_CONFIG
  echo "TDH_TKGMC_CLUSTER_CIDR=10.96.0.0/16"                                                                    >> $TMC_DEPLOMENT_CONFIG

  mkdir -p $HOME/.tanzu-demo-hub/config
  CLUSTER_TEMPLATE=$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}_template.yaml
  echo "# ClusterAPI Examples for Provisioning Tanzu Kubernetes Clusters"                                                         >  $CLUSTER_TEMPLATE
  echo "# https://docs.vmware.com/en/VMware-vSphere/7.0/vmware-vsphere-with-tanzu/GUID-B1034373-8C38-4FE2-9517-345BF7271A1E.html" >> $CLUSTER_TEMPLATE
  echo "apiVersion: run.tanzu.vmware.com/v1alpha1"                                                                                >> $CLUSTER_TEMPLATE
  echo "kind: TanzuKubernetesCluster"                                                                                             >> $CLUSTER_TEMPLATE
  echo "metadata:"                                                                                                                >> $CLUSTER_TEMPLATE
  echo "  name: tkgs-cluster-1"                                                                                                   >> $CLUSTER_TEMPLATE
  echo "  namespace: tanzu-demo-hub"                                                                                              >> $CLUSTER_TEMPLATE
  echo "spec:"                                                                                                                    >> $CLUSTER_TEMPLATE
  echo "  distribution:"                                                                                                          >> $CLUSTER_TEMPLATE
  echo "    version: v1.20"                                                                                                       >> $CLUSTER_TEMPLATE
  echo "  topology:"                                                                                                              >> $CLUSTER_TEMPLATE
  echo "    controlPlane:"                                                                                                        >> $CLUSTER_TEMPLATE
  echo "      count: 1"                                                                                                           >> $CLUSTER_TEMPLATE
  echo "      class: guaranteed-small"                                                                                            >> $CLUSTER_TEMPLATE
  echo "      storageClass: pacific-gold-storage-policy"                                                                          >> $CLUSTER_TEMPLATE
  echo "    workers:"                                                                                                             >> $CLUSTER_TEMPLATE
  echo "      count: 3"                                                                                                           >> $CLUSTER_TEMPLATE
  echo "      class: guaranteed-small-medium"                                                                                     >> $CLUSTER_TEMPLATE
  echo "      storageClass: pacific-gold-storage-policy"                                                                          >> $CLUSTER_TEMPLATE

  messageTitle "Create the TKG Management Cluster deployment File"
  messagePrint " ▪ TKG Deployment File"          "$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml"
  messagePrint " ▪ TDH Configuration"            "$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.cfg"
  messagePrint " ▪ Management Cluster"           "$TDH_TKGMC_NAME"
  messagePrint " ▪ Cloud Infrastructure"         "$TDH_DEPLOYMENT_ENV_NAME"

  mkdir -p $HOME/.tanzu/tkg/clusterconfigs

  STORAGE_CLASS=$(kubectl get storageclasses | sed '1d' | head -1 | awk '{ print $1 }')

  DEPLOYMENT_FILE=${HOME}/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.cfg
  TKG_WC_CONFIG_DEV="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-dev.yaml"
  TKG_WC_CONFIG_PRD="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-prod.yaml"
  TKG_MC_CONFIG="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml"

  echo "TDH_TKGMC_INFRASTRUCTURE=$TDH_DEPLOYMENT_ENV_NAME"                            >  $DEPLOYMENT_FILE
  echo "TDH_TKGMC_NAME=$TDH_TKGMC_NAME"                                               >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_ENVNAME=$TDH_TKGMC_ENVNAME"                                         >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_TKG_TYPE=TKGs"                                                      >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_CONFIG=${TDH_TKGMC_NAME}.yaml"                                      >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_DEV=${TDH_TKGMC_NAME}-wc-dev.yaml"                        >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_PROD=${TDH_TKGMC_NAME}-wc-prod.yaml"                      >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_KUBECONFIG=${TDH_TKGMC_NAME}.kubeconfig"                            >> $DEPLOYMENT_FILE


  echo "WORKER_STORAGE_CLASS: $STORAGE_CLASS"                            >  $TKG_MC_CONFIG
  echo "CONTROL_PLANE_STORAGE_CLASS: $STORAGE_CLASS"                     >> $TKG_MC_CONFIG
  echo "DEFAULT_STORAGE_CLASS: $STORAGE_CLASS"                           >> $TKG_MC_CONFIG
  echo "NAMESPACE: tanzu-demo-hub"                                       >> $TKG_MC_CONFIG
  echo "INFRASTRUCTURE_PROVIDER: tkg-service-vsphere"                    >> $TKG_MC_CONFIG
  echo "WORKER_VM_CLASS: guaranteed-small"                               >> $TKG_MC_CONFIG
  echo "CONTROL_PLANE_VM_CLASS: guaranteed-small"                        >> $TKG_MC_CONFIG
  echo "SERVICE_DOMAIN: $VSPHERE_DNS_DOMAIN"                             >> $TKG_MC_CONFIG

  messageTitle "Create config file for TKG Workload Clusters"
  messagePrint " ▪ Deployment File (dev)"      "~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-dev.yaml"
  messagePrint " ▪ Deployment File (prod)"     "~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-prod.yaml"

  # --- CONFIG FOR PROD AND DEV ---
  cat $TKG_MC_CONFIG > $TKG_WC_CONFIG_DEV
  cat $TKG_MC_CONFIG > $TKG_WC_CONFIG_PRD
  echo "CLUSTER_PLAN: dev"             >>  $TKG_WC_CONFIG_DEV
  echo "CLUSTER_PLAN: prod"            >>  $TKG_WC_CONFIG_PRD

  WC_DEV_PATH=$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-dev.yaml
  WC_PRD_PATH=$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-prod.yaml
  messageLine
  printf "\e[1m1.) vCenter WebAccess Access ($VSPHERE_VCENTER_SERVER)\e[0m\n"
  echo "    => http://$VSPHERE_VCENTER_SERVER  ($VSPHERE_VCENTER_ADMIN/$VSPHERE_VCENTER_PASSWORD)"
  printf "\e[1m2.) vCenter CLI Access ($VSPHERE_VCENTER_SERVER)\e[0m\n"

  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ export GOVC_INSECURE=1"
    echo "       tdh-tools:/$ export GOVC_URL=https://${VSPHERE_VCENTER_SERVER}/sdk"
    echo "       tdh-tools:/$ export GOVC_USERNAME=$VSPHERE_VCENTER_ADMIN"
    echo "       tdh-tools:/$ export GOVC_PASSWORD=$VSPHERE_VCENTER_PASSWORD"
    echo "       tdh-tools:/$ govc ls /*/host/Workload-Cluster"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => export GOVC_INSECURE=1"
    echo "    => export GOVC_URL=https://${VSPHERE_VCENTER_SERVER}/sdk"
    echo "    => export GOVC_USERNAME=$VSPHERE_VCENTER_ADMIN"
    echo "    => export GOVC_PASSWORD=$VSPHERE_VCENTER_PASSWORD"
    echo "    => govc ls /*/host/Workload-Cluster"
  fi

  printf "\e[1m3.) login into the Supervisor Cluster\e[0m\n"
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ xport KUBECTL_VSPHERE_PASSWORD=$VSPHERE_VCENTER_PASSWORD"
    echo "       tdh-tools:/$ kubectl vsphere login --insecure-skip-tls-verify --server $VSPHERE_API_SERVER -u administrator@vsphere.local"
    echo "       tdh-tools:/$ kubectl config use-context wcp.${VSPHERE_DNS_DOMAIN}"
    echo "       tdh-tools:/$ tanzu login --name $TDH_TKGMC_NAME --kubeconfig ~/.kube/config --context wcp.$VSPHERE_DNS_DOMAIN"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => export KUBECTL_VSPHERE_PASSWORD=$VSPHERE_VCENTER_PASSWORD"
    echo "    => kubectl vsphere login --insecure-skip-tls-verify --server $VSPHERE_API_SERVER -u administrator@vsphere.local"
    echo "    => kubectl config use-context wcp.${VSPHERE_DNS_DOMAIN}"
    echo "    => tanzu login --name $TDH_TKGMC_NAME --kubeconfig ~/.kube/config --context wcp.$VSPHERE_DNS_DOMAIN"
  fi

  printf "\e[1m4.) Create Kubernetes Cluster with the ClusterAPI\e[0m\n"
  echo "    Adjust parameters such as cluster name and kubernetes version if you are not happy woth the" 
  echo "    default settings."
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ kubectl apply  -f $CLUSTER_TEMPLATE   ## Create the k8s Clusteer"
    echo "       tdh-tools:/$ => kubectl get tanzukubernetesclusters -n tanzu-demo-hub"
    echo "       tdh-tools:/$ => kubectl describe tanzukubernetescluster -n tanzu-demo-hub tkgs-cluster-1"
    echo "       tdh-tools:/$ => kubectl delete -f $CLUSTER_TEMPLATE   ## Delete the k8s Clusteer"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => kubectl apply  -f $CLUSTER_TEMPLATE   ## Create the k8s Clusteer"
    echo "    ?> kubectl get tanzukubernetesclusters -n tanzu-demo-hub"
    echo "    => kubectl describe tanzukubernetescluster -n tanzu-demo-hub tkgs-cluster-1"
    echo "    => kubectl delete -f $CLUSTER_TEMPLATE   ## Delete the k8s Clusteer"
  fi

  printf "\e[1m5.) Create Kubernetes Cluster with Tanzu CLI\e[0m\n"
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ tanzu config server list"
    echo "       tdh-tools:/$ tanzu kubernetes-release get"
    echo "       tdh-tools:/$ tanzu cluster create --file $WC_DEV_PATH --tkr=\"v1.20.2---vmware.1-tkg.1.1d4f79a\" <cluster-name> -y"
    echo "       tdh-tools:/$ anzu cluster create --file $WC_PRD_PATH --tkr=\"v1.18.5---vmware.1-tkg.1.c40d30d\" <cluster-name> -y"
    echo "       tdh-tools:/$ tanzu cluster list"
    echo "       tdh-tools:/$ tanzu cluster delete -n tanzu-demo-hub <cluster-name> -y"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => tanzu config server list"
    echo "    => tanzu kubernetes-release get"
    echo "    => tanzu cluster create --file $WC_DEV_PATH --tkr=\"v1.20.2---vmware.1-tkg.1.1d4f79a\" <cluster-name> -y"
    echo "    => tanzu cluster create --file $WC_PRD_PATH --tkr=\"v1.18.5---vmware.1-tkg.1.c40d30d\" <cluster-name> -y"
    echo "    => tanzu cluster list"
    echo "    => tanzu cluster delete -n tanzu-demo-hub <cluster-name> -y"
  fi

  printf "\e[1m6.) Create TKG Cluster for Tanzu-Demo-Hub\e[0m\n"
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ kubectl config set-context $VSPHERE_API_SERVER"
    echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-${TDH_DEPLOYMENT_ENV_NAME}-${TDH_USER}"
    echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-${TDH_DEPLOYMENT_ENV_NAME}-${TDH_USER} -k \"v1.17.16---vmware.2-tkg.1\""
    echo "       tdh-tools:/$ exit"
  else
    echo "    => kubectl config set-context $VSPHERE_API_SERVER"
    echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-${TDH_DEPLOYMENT_ENV_NAME}-${TDH_USER}"
    echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-${TDH_DEPLOYMENT_ENV_NAME}-${TDH_USER} -k \"v1.17.16---vmware.2-tkg.1\""
  fi

  printf "\e[1m7.) Create Kubernetes Cluster through Tanzu Mission Control (TMC) ***UNSTABLE*** \e[0m\n"
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/tdh-tools.sh"
    echo "       tdh-tools:/$ ./deployTMC tmc-vsphere-${TDH_USER}.cfg"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => ./deployTMC tmc-vsphere-${TDH_USER}.cfg"
  fi
  messageLine

  # Tanzu Kubernetes Cluster Operational Commands
  # https://docs.vmware.com/en/VMware-vSphere/7.0/vmware-vsphere-with-tanzu/GUID-232CCCF3-CCC1-4D7E-B67C-64590CB891DD.html
else
  #########################################################################################################################
  ############################## TANZU KUBERNETS GRID FOR AWS, AZURE AND VPSHERE (TKGm) ###################################
  #########################################################################################################################

  if [ "${TDH_TKGMC_TKG_TYPE}" == "tkgm" ]; then
    $SSH_COMMAND -n "[ -f $SSH_HOME/tanzu-demo-hub/scripts/uploadOVAimages.sh ] && tanzu-demo-hub/scripts/uploadOVAimages.sh $DEPLOY_TKG_TEMPLATE $DEBUG"
  fi

  cnt=$(tanzu management-cluster get 2>/dev/null | grep -c " $TDH_TKGMC_NAME ")
  if [ $cnt -eq 0 ]; then
    # --- ACCEPT LICENSE AGREEMENT ---
    if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
      messageTitle "Accepting Image Terms for Provider (vmware-inc) / Offer: (tkg-capi)"
      #[ ! -d $HOME/.tanzu-demo-hub/cache/azure-eula ] && mkdir -p $HOME/.tanzu-demo-hub/cache/azure-eula

      cmdLoop az vm image list --publisher vmware-inc --offer tkg-capi --all > /tmp/output.json
      for img in $(jq -r '.[].urn' /tmp/output.json | egrep -v "2020|2021" | \
                   awk -F: '{ printf("%s:%s:%s\n",$1,$2,$3)}' | sort | uniq); do
        stt=$(az vm image terms show --urn $img:latest | jq -r '.accepted')

        if [ "$stt" != "true" ]; then 
          messagePrint " ▪ Accepting Image Terms for image ($img)" "$img"

          cnt=0; ret=1
          while [ $ret -ne 0 -a $cnt -lt 5 ]; do
            #az vm image terms accept --urn $img > /dev/null 2>&1; ret=$?
            az vm image terms accept --urn $img:latest > /dev/null 2>&1; ret=$?
            [ $ret -eq 0 ] && break
            let cnt=cnt+1
            sleep 30
          done

          if [ $ret -ne 0 ]; then 
            echo "ERROR: failed to accept image terms after $cnt tries, please try manually"
            echo "       => az vm image terms accept --urn $img:latest"
            exit
          fi
        fi
      done
    fi

    # --- VERIFY IF DOCKER IS RUNNING ---
    if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then
      docker ps > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Docker Daemon not running"; exit
        exit 1
      fi
    fi

    # --- CREATE MANAGEMENT CLUSTER ---
    [ ! -d ~/.tanzu-demo-hub/config ] && mkdir -p ~/.tanzu-demo-hub/config

    # --- FIX FOR KIND (https://kb.vmware.com/s/article/85245)
    $SSH_COMMAND -n "sudo sysctl net/netfilter/nf_conntrack_max=131072 > /dev/null 2>&1"

    CMDEXE="scripts/InstallTKGmc.sh"
    CMDDIR="$SSH_HOME/tanzu-demo-hub"
    $SSH_TTY -n "[ -f $CMDDIR/$CMDEXE ] && cd $CMDDIR && $CMDEXE \"$DEPLOY_TKG_TEMPLATE\" \"$TDH_TKGMC_NAME\" \"$DEBUG\" \"$TDH_TOOLS_CONTAINER_TYPE\" \"$DEPLOY_TKG_VERSION\""; ret=$?
    if [ ${ret} -ne 0 ]; then
      echo "ERROR: Failed to deploy Management Server on $JUMP_HOST"
      echo "       => $SSH_DISPLAY -n \"cd $CMDDIR && $CMDEXE $DEPLOY_TKG_TEMPLATE $TDH_TKGMC_NAME $DEBUG $TDH_TOOLS_CONTAINER_TYPE $DEPLOY_TKG_VERSION\""
      exit 1
    fi

    cleanKubeconfig           $HOME/.kube/config
    cleanKubeconfig           $HOME/.kube-tkg/config
    #cleanKubeconfig           $HOME/.config/tanzu/config.yaml
    cleanManagementCluster

    # --- LOGIN ---
    tanzu login --server $TDH_TKGMC_NAME > /dev/null 2>&1

    cnt=$(tanzu management-cluster get 2>/dev/null | grep -c " $TDH_TKGMC_NAME ")
    if [ $cnt -eq 0 ]; then
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig ~/.tanzu-demo-hub/config > /dev/null 2>&1
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml ~/.tanzu-demo-hub/config > /dev/null 2>&1

      if [ ! -f $HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig ]; then 
        echo "ERROR: failed to copy ${TDH_TKGMC_NAME}.kubeconfig"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/${TDH_TOOLS}.sh"
          echo "          tdh-tools:/$ $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig ~/.tanzu-demo-hub/config"
          echo "          tdh-tools:/$ exit"
        else
          echo "       => $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig ~/.tanzu-demo-hub/config"
        fi

        exit 1
      fi

      # --- UNCOMMENT FOR DEBUGGING ---
      #echo "tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig \
      #  --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME"

      tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig  --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME \
         --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
      tanzu login --server $TDH_TKGMC_NAME > /dev/null 2>&1
      tanzu management-cluster get > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: failed to login to TKG Management Cluster: ${TDH_TKGMC_NAME}.kubeconfig"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/${TDH_TOOLS}.sh"
          echo "          tdh-tools:/$ tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig  \\"
          echo "                         --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME \\"
          echo "                         --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME"
          echo "          tdh-tools:/$ tmc login --name $TMC_CONTEXT_NAME --no-configure"
          echo "          tdh-tools:/$ exit"
          echo "       => Verify you API token, mabe a new token is required"
          echo "          TMC => My Account => API Token"
        else
          echo "       => export TMC_API_TOKEN=$TMC_SERVICE_TOKEN"
          echo "       => tmc login --name $TMC_CONTEXT_NAME --no-configure"
          echo "       => Verify you API token, mabe a new token is required"
          echo "          TMC => My Account => API Token"
        fi

        echo "       => tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig  \\"
        echo "            --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME \\"
        echo "            --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME"
        echo "       => tanzu login --server $TDH_TKGMC_NAME"
        echo "       => tanzu management-cluster get"
        exit
      fi
    fi

    tanzu management-cluster kubeconfig get --admin > /dev/null 2>&1
    kubectl config set-cluster $TDH_TKGMC_NAME > /dev/null 2>&1
    kubectl config use-context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
  else
    # --- RECONFIGURE KUBECONFIG OF THE MANAGEMENT CLUSTER ---
    [ ! -d ~/.kube-tkg ] && mkdir -p ~/.kube-tkg
    [ ! -f ~/.kube-tkg/config ] && touch ~/.kube-tkg/config

    cnt=$(grep -c $TDH_TKGMC_NAME ~/.kube-tkg/config 2>/dev/null) 
    if [ $cnt -eq 0 ]; then 
      tanzu management-cluster kubeconfig get --admin > /dev/null 2>&1
      kubectl config set-cluster $TDH_TKGMC_NAME > /dev/null 2>&1
      kubectl config use-context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
    fi
  fi

  # --- VERIFY TMC REGISTRATION
  cmdLoop tmc managementcluster list -o json > /tmp/output.json
  nam=$(jq -r --arg key "$TDH_TKGMC_NAME" '.managementClusters[] | select(.fullName.name == $key).fullName.name' /tmp/output.json)
  if [ "$nam" == "$TDH_TKGMC_NAME" ]; then
    st1=$(jq -r --arg key "$TDH_TKGMC_NAME" '.managementClusters[] | select(.fullName.name == $key).status.phase' /tmp/output.json)
    st2=$(jq -r --arg key "$TDH_TKGMC_NAME" '.managementClusters[] | select(.fullName.name == $key).status.health' /tmp/output.json)
    [ "$st1" == "null" -o "$st1" == "" ] && stt="NOT READY / $st2" || stt="$st1 / $st2"

    if [ "$st1" != "READY" -o "$st2" != "HEALTHY"  ]; then 
      messagePrint " ▪ TMC DeRegister Cluster"             "$TDH_TKGMC_NAME"
      #tmc managementcluster deregister $TDH_TKGMC_NAME -k $HOME/.kube/config > /tmp/error.log 2>&1; ret=$?

      tmc managementcluster delete $TDH_TKGMC_NAME -f > /tmp/error.log 2>&1; ret=$?
      if [ $ret -ne 0 ]; then
        logMessages /tmp/error.log
        echo "ERROR: failed to deregister Management Cluster $TDH_TKGMC_NAME, please try manually"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/${TDH_TOOLS}.sh"
          echo "          tdh-tools:/$ tmc managementcluster delete $TDH_TKGMC_NAME -f"
          echo "          tdh-tools:/$ exit"
        else
          echo "       => tmc managementcluster delete $TDH_TKGMC_NAME -f"
        fi

        exit 1
      fi

      cnt=1
      while [ $cnt -ne 0 ]; do
        messagePrint " ▪ TMC DeRegister Cluster"             "waiting"
        cnt=$(tmc managementcluster list | grep -c $TDH_TKGMC_NAME)

        sleep 30
      done
    fi
  fi


  cmdLoop tmc managementcluster list -o json > /tmp/output.json
  nam=$(jq -r --arg key "$TDH_TKGMC_NAME" '.managementClusters[] | select(.fullName.name == $key).fullName.name' /tmp/output.json)
  if [ "$nam" == "" ]; then
    messagePrint " ▪ TMC Register Cluster"             "$TDH_TKGMC_NAME"

    ret=1; cnt=0
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG --kubeconfig=$HOME/.kube/config > /tmp/error.log 2>&1; ret=$?
      if [ $ret -eq 0 ]; then
        tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1; ret=$?
        if [ $ret -eq 0 ]; then break; else ret=1; fi
      fi
      sleep 30
      let cnt=cnt+1
    done

    if [ $ret -ne 0 ]; then
      logMessages /tmp/error.log
      echo "ERROR: failed to register TKG Management Cluster: $TDH_TKGMC_NAME to TMC"
      if [ "$NATIVE" == "0" ]; then
        echo "       => tools/${TDH_TOOLS}.sh"
        echo "          tdh-tools:/$ tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG -k $HOME/.kube/config"
        echo "          tdh-tools:/$ exit"
      else
        echo "       => tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG -k $HOME/.kube/config"
      fi

      exit 1
    fi

    cnt=0; stt="PENDING"
    while [ "$stt" != "READY" -a $cnt -lt 10 ]; do
      stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.phase') 
      sleep 60
 
      let cnt=cnt+1
    done
  fi

  # --- CLEANUP OLD MANAGEMENT CLUSTERS ---
  #cleanKubeconfig $HOME/.tanzu/config.yaml  => cleanManagementCluster

  messageTitle "Create the TKG Management Cluster deployment File"
  messagePrint " ▪ TDH Deployment File"          "$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml"
  messagePrint " ▪ TDH Configuration"            "$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.cfg"
  messagePrint " ▪ Management Cluster"           "$TDH_TKGMC_NAME"
  messagePrint " ▪ Cloud Infrastructure"         "$TDH_DEPLOYMENT_ENV_NAME"

  mkdir -p $HOME/.tanzu/tkg/clusterconfigs

  DEPLOYMENT_FILE=${HOME}/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.cfg
  TKG_WC_CONFIG_DEV="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-dev.yaml"
  TKG_WC_CONFIG_PRD="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-prod.yaml"
  TKG_MC_CONFIG="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml"

  TMC_CONFIG_NAME="$(echo ${TDH_TKGMC_NAME} | sed 's/tkgmc/tmc/g')"
  CONFIG_FILE="$HOME/.tanzu-demo-hub/config/${TMC_CONFIG_NAME}.cfg"

  echo "TDH_TKGMC_INFRASTRUCTURE=$TDH_DEPLOYMENT_ENV_NAME"                            >  $DEPLOYMENT_FILE
  echo "TDH_TKGMC_NAME=$TDH_TKGMC_NAME"                                               >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_ENVNAME=$TDH_TKGMC_ENVNAME"                                         >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_TMC_CONFIG=${TMC_CONFIG_NAME}.cfg"                                  >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_CONFIG=${TDH_TKGMC_NAME}.yaml"                                      >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_DEV=${TDH_TKGMC_NAME}-wc-dev.yaml"                        >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_PROD=${TDH_TKGMC_NAME}-wc-prod.yaml"                      >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_KUBECONFIG=${TDH_TKGMC_NAME}.kubeconfig"                            >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_TOOLS_CONTAINER=${TDH_TOOLS}"                                       >> $DEPLOYMENT_FILE

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "Azure" ]; then
    echo ""                                                                           >> $DEPLOYMENT_FILE
    echo "nodes[0]='Standard_D2s_v3'   ## Azure Standard_D2s_v3 (2 Cores, 8 GB RAM)"  >> $DEPLOYMENT_FILE
    echo "nodes[1]='Standard_D4s_v3'   ## Azure Standard_D4s_v3 (2 Cores, 8 GB RAM)"  >> $DEPLOYMENT_FILE
    echo "nodes[2]='Standard_D8s_v3'   ## Azure Standard_D8s_v3 (4 Cores, 16 GB RAM)" >> $DEPLOYMENT_FILE
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "AWS" ]; then
    echo ""                                                                           >> $DEPLOYMENT_FILE
    echo "nodes[0]='m5.large'          ## AWS m5.large   (2 Cores, 8 GB RAM)"         >> $DEPLOYMENT_FILE
    echo "nodes[1]='m5.xlarge'         ## AWS m5.xlarge  (2 Cores, 8 GB RAM)"         >> $DEPLOYMENT_FILE
    echo "nodes[2]='m5.2xlarge'        ## AWS m5.2xlarge (4 Cores, 16 GB RAM)"        >> $DEPLOYMENT_FILE
  fi

  #echo "TDH_TKGMC_PLAN=dev"                                                     >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CEIP_PARTICIPATION=true"                                      >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CNI=antrea"                                                   >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_LOGLEVEL=1"                                                   >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_SERVICE_CIDR=100.64.0.0/13"                                   >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CLUSTER_CIDR=100.96.0.0/11"                                   >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_MACHINE_HEALTH_CHECK_ENABLED=true"                            >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_MACHINE_TYPE=Standard_D2s_v3"                                 >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CONTROL_PLANE_MACHINE_TYPE=Standard_D2s_v3"                   >> $DEPLOYMENT_FILE

  messageTitle "Create config file for TMC Management Cluster"
  messagePrint " ▪ Deployment File (dev)"      "$CONFIG_FILE"
  echo "TDH_INFRASTRUCTURE=tmc"                                                     >  $CONFIG_FILE
  echo "TDH_ENVNAME=tkgm"                                                           >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_CLOUD=$TDH_DEPLOYMENT_ENV_NAME"                              >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_DESCRIPTION='Tanzu Kubernetes Grid (TKGm) on Azure'"         >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_MAINTAINER=$TDH_USER"                                        >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_DEBUG=false"                                                 >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_CLUSTERGROUP=tanzu-demo-hub"                                 >> $CONFIG_FILE
  echo "TDH_MANAGEMENT_CLUSTER=$TDH_TKGMC_NAME"                                     >> $CONFIG_FILE
  echo "TDH_DEPLOYMENT_CLUSTER_PLAN=dev"                                            >> $CONFIG_FILE

  echo "# THILS VALUES HAS BEEN GENERATED, DONT EDIT MANUALLY"                      >> $CONFIG_FILE
  tanzu kubernetes-release get | egrep " v" | awk '{ printf("# TMC_K8S_VERSIONS:%s:%s:%s:%s\n",$1,$2,$3,$4)}' >> $CONFIG_FILE


  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "Azure" ]; then
    str=$(tanzu kubernetes-release get 2>/dev/null | egrep " v" | awk '{ print $1 }') 
    for n in $str; do
      tanzu kubernetes-release os get $n | sed '1d' | awk -v n="$n" '{ printf("# TMC_K8S_OS_REL:%s:%s:%s:%s\n",n,$1,$2,$3)}' >> $CONFIG_FILE
    done

    echo ""                                                                           >> $CONFIG_FILE
    echo "nodes[0]='Standard_D2s_v3'   ## Azure Standard_D2s_v3 (2 Cores, 8 GB RAM)"  >> $CONFIG_FILE
    echo "nodes[1]='Standard_D4s_v3'   ## Azure Standard_D4s_v3 (2 Cores, 8 GB RAM)"  >> $CONFIG_FILE
    echo "nodes[2]='Standard_D8s_v3'   ## Azure Standard_D8s_v3 (4 Cores, 16 GB RAM)" >> $CONFIG_FILE
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "AWS" ]; then
    str=$(tanzu kubernetes-release get 2>/dev/null | egrep " v" | awk '{ print $1 }') 
    for n in $str; do
      tanzu kubernetes-release os get $n --region $AWS_REGION | sed '1d' | awk -v n="$n" '{ printf("# TMC_K8S_OS_REL:%s:%s:%s:%s\n",n,$1,$2,$3)}' >> $CONFIG_FILE
    done

    echo ""                                                                           >> $CONFIG_FILE
    echo "nodes[0]='m5.large'          ## AWS m5.large   (2 Cores, 8 GB RAM)"         >> $CONFIG_FILE
    echo "nodes[1]='m5.xlarge'         ## AWS m5.xlarge  (2 Cores, 8 GB RAM)"         >> $CONFIG_FILE
    echo "nodes[2]='m5.2xlarge'        ## AWS m5.2xlarge (4 Cores, 16 GB RAM)"        >> $CONFIG_FILE
  fi

  messageTitle "Create config file for TKG Workload Clusters"
  messagePrint " ▪ Deployment File (dev)"      "~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-dev.yaml"
  messagePrint " ▪ Deployment File (prod)"     "~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}-wc-prod.yaml"

  # --- CONFIG FOR PROD AND DEV ---
  idp=$(egrep "^IDENTITY_MANAGEMENT_TYPE:" $TKG_MC_CONFIG | awk '{ print $NF }')
  echo "CLUSTER_PLAN: dev"             >  $TKG_WC_CONFIG_DEV
  echo "CLUSTER_PLAN: prod"            >  $TKG_WC_CONFIG_PRD

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "AWS" ]; then
    var_aws_1="AWS_REGION:|AWS_NODE_AZ:|AWS_ACCESS_KEY_ID:|AWS_SECRET_ACCESS_KEY:|AWS_SSH_KEY_NAME:|AWS_AMI_ID:"
    var_aws_2="CONTROL_PLANE_MACHINE_TYPE:|NODE_MACHINE_TYPE:"

    egrep "$var_aws_1|$var_aws_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_PRD
    egrep "$var_aws_1|$var_aws_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "vSphere" ]; then
    var_azure_1="AZURE_TENANT_ID:|AZURE_CLIENT_ID:|AZURE_CLIENT_SECRET:|AZURE_SSH_PUBLIC_KEY_B64:|AZURE_CONTROL_PLANE_MACHINE_TYPE:"
    var_azure_2="AZURE_LOCATION:|AZURE_NODE_MACHINE_TYPE:|AZURE_SUBSCRIPTION_ID:"

    egrep "VSPHERE" $TKG_MC_CONFIG | egrep -v "VSPHERE_CONTROL_PLANE_ENDPOINT"     >> $TKG_WC_CONFIG_PRD
    egrep "VSPHERE" $TKG_MC_CONFIG | egrep -v "VSPHERE_CONTROL_PLANE_ENDPOINT"     >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "Azure" ]; then 
    var_azure_1="AZURE_TENANT_ID:|AZURE_CLIENT_ID:|AZURE_CLIENT_SECRET:|AZURE_SSH_PUBLIC_KEY_B64:|AZURE_CONTROL_PLANE_MACHINE_TYPE:"
    var_azure_2="AZURE_LOCATION:|AZURE_NODE_MACHINE_TYPE:|AZURE_SUBSCRIPTION_ID:"

    egrep "$var_azure_1|$var_azure_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_PRD
    egrep "$var_azure_1|$var_azure_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_DEV
  fi
    
  if [ "$idp" == "ldap" ]; then
    var_ldap="LDAP_HOST:|LDAP_GROUP_SEARCH_NAME_ATTRIBUTE:|LDAP_GROUP_SEARCH_USER_ATTRIBUTE:|LDAP_USER_SEARCH_USERNAME:"

    egrep "$var_ldap" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_PRD
    egrep "$var_ldap" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$idp" == "oidc" ]; then
    egrep "^OIDC_|IDENTITY_MANAGEMENT_TYPE" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_DEV
    egrep "^OIDC_|IDENTITY_MANAGEMENT_TYPE" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_PRD
  fi

  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ] && CLOUD="vsphere"
  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ] && CLOUD="azure"
  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ] && CLOUD="aws"
  
  echo "-----------------------------------------------------------------------------------------------------------"
  #$SSH_COMMAND -n "tanzu management-cluster get 2>/dev/null | sed -n '/^  NAME /,/^NAME/p' | egrep -v \"^NAME\" "
  tanzu config server list 
  echo "-----------------------------------------------------------------------------------------------------------"
  printf "\e[1m1.) Access to the Jump Server and verify Deployment\e[0m\n"
  echo "    => $SSH_COMMAND"
  echo "    => tanzu management-cluster get"
  printf "    => %-80s %s\n" "kubectl config set-cluster $TDH_TKGMC_NAME" "# Set k8s Context to mc Cluster"
  printf "    => %-80s %s\n" "kubectl config set-context ${TDH_TKGMC_NAME}-admin@${TDH_TKGMC_NAME}" "# Set k8s Context to mc Cluster"
  printf "    => %-80s %s\n" "kubectl get cluster --all-namespaces" "# Set k8s Context to the TKG Management Cluster"
  printf "    => %-80s %s\n" "kubectl get kubeadmcontrolplane,machine,machinedeployment --all-namespaces" "# To verify the first control plane is up"
  printf "    => %-80s %s\n" "tanzu login --server $TDH_TKGMC_NAME" "# Show Tanzu Management Cluster"
  printf "    => %-80s %s\n" "tanzu management-cluster get" "# Show Tanzu Management Cluster"
  
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then
    printf "\e[1m2.) Ceeate TKG Workload Cluster\e[0m\n"
    echo "    TKG Workload Cluster 01 ...............................: NAME_TAG: TKG_CLUSTER_01"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER01_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER01_LOADBALANCER_POOL"
    echo "    TKG Workload Cluster 02 ...............................: NAME_TAG: TKG_CLUSTER_02"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER02_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER02_LOADBALANCER_POOL"
    echo "    TKG Workload Cluster 03 ...............................: NAME_TAG: TKG_CLUSTER_03"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER03_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER03_LOADBALANCER_POOL"
    echo ""

    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/${TDH_TOOLS}.sh"
      echo "       tdh-tools:/$ export CLUSTER_NAME=<cluster_name>                   ## Workload Cluster Name"
      echo "       tdh-tools:/$ export VSPHERE_CONTROL_PLANE_ENDPOINT=<ip-address>   ## Control Plane IP Adress for the worklaod Cluster"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml --tkr v1.20.4---vmware.3-tkg.1"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"
      echo "       tdh-tools:/$ tanzu cluster kubeconfig get \$CLUSTER_NAME --admin"
      echo "       tdh-tools:/$ kubectl config use-context \${CLUSTER_NAME}-admin@\$CLUSTER_NAME"
      echo "       tdh-tools:/$ tanzu cluster list --include-management-cluster"
      echo "       tdh-tools:/$ tanzu cluster delete \$CLUSTER_NAME -y"
      echo "       tdh-tools:/$ exit"
    else
      echo "    => export CLUSTER_NAME=<cluster_name>                   ## Workload Cluster Name"
      echo "    => export VSPHERE_CONTROL_PLANE_ENDPOINT=<ip-address>   ## Control Plane IP Adress for the worklaod Cluster"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml --tkr v1.20.4---vmware.3-tkg.1"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"
      echo "    => tanzu cluster kubeconfig get \$CLUSTER_NAME --admin"
      echo "    => kubectl config use-context \${CLUSTER_NAME}-admin@\$CLUSTER_NAME"
      echo "    => tanzu cluster list --include-management-cluster"
      echo "    => tanzu cluster delete \$CLUSTER_NAME -y"
    fi
  else
    printf "\e[1m2.) Ceeate TKG Workload Cluster\e[0m\n"
    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/${TDH_TOOLS}.sh"
      echo "       tdh-tools:/$ tanzu kubernetes-release get"
      #echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml  <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      #echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml <cluster-name>"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml  <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml <cluster-name>"
      echo "       tdh-tools:/$ tanzu cluster kubeconfig get <cluster-name> --admin"
      echo "       tdh-tools:/$ tanzu cluster list --include-management-cluster"
      echo "       tdh-tools:/$ exit"
    else
      echo "    => tanzu kubernetes-release get"
      #echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml  <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      #echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml <cluster-name>"
      echo "    => tanzu cluster create -f \$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml <cluster-name>"
      echo "    => tanzu cluster create -f \$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      echo "    => tanzu cluster kubeconfig get <cluster-name> --admin"
      echo "    => tanzu cluster list --include-management-cluster"
    fi
  fi

  printf "\e[1m2.) Ceeate Tanzu Demo Hub (TDH) Workload Cluster with services (TBS, Harbor, Ingres etc.)\e[0m\n"
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then
    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/${TDH_TOOLS}.sh"
      echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_01"
      echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_02 -k \"v1.20.8---vmware.1-tkg.2\""
      echo "       tdh-tools:/$ exit"
    else
      echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_01"
      echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_02 -k \"v1.20.8---vmware.1-tkg.2\""
    fi
  else
    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/${TDH_TOOLS}.sh"
      echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER"
      echo "       tdh-tools:/$ ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -k \"v1.20.8---vmware.1-tkg.2\""
      echo "       tdh-tools:/$ exit"
    else
      echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER"
      echo "    => ./deployTKG -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -k \"v1.20.8---vmware.1-tkg.2\""
    fi
  fi

#  printf "\e[1m3.) Delete the Management Cluster (Local or on the Jump host)\e[0m\n"
#  if [ "$NATIVE" == "0" ]; then
#    echo "    => tools/tdh-tools.sh"
#    echo "       tdh-tools:/$ tanzu management-cluster delete $TDH_TKGMC_NAME -y"
#    echo "       tdh-tools:/$ exit"
#    echo "    => $SSH_DISPLAY"
#    #echo "       tanzu management-cluster delete $TDH_TKGMC_NAME -y"
#    echo "       deployTKGmc $DEPLOY_TKG_TEMPLATE --delete"
#  else
#    echo "    => tanzu management-cluster delete $TDH_TKGMC_NAME -y"
#  fi

  printf "\e[1m3.) Delete the Management Cluster\e[0m\n"
  echo "    => ./deployTKGmc -d $DEPLOY_TKG_TEMPLATE --delete -v <version>"

  printf "\e[1m4.) Login to Jump Server: $JUMP_HOST (only if required)\e[0m\n"
  echo "    => $SSH_DISPLAY"
  echo ""
  echo "-----------------------------------------------------------------------------------------------------------"
fi

exit

tanzu management-cluster create -y --file vs1.yaml 

# --- CHECK STATUS OF MANAGEMENT CLUSTER ---
kubectl --kubeconfig .kube-tkg/config get pods -A

